{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as pl\n",
    "import scipy as sp\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imported necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class to add layers :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer:\n",
    "\n",
    "\tdef __init__(self,inpSize,outSize) : \n",
    "\t\t\n",
    "\t\tself.inpSize = inpSize\n",
    "\t\tself.outSize = outSize\n",
    "\t\tself.weights = (np.random.rand(outSize,inpSize)-0.5)/10 # weights initialised randomly between (-0.5,0.5)\n",
    "\t\tself.biases = (np.random.rand(outSize,1)-0.5)# biases initialised randomly between (-0.5,0.5)\n",
    "\t\tself.out = np.zeros((outSize,1))\n",
    "\n",
    "\tdef forwardPass(self,inp):\n",
    "\t\tself.inp = inp \n",
    "\t\tout1 = self.weights.dot(inp) + self.biases\n",
    "\t\tself.out = out1\n",
    "\t\treturn out1\n",
    "\n",
    "\tdef backPass(self,forwDeriv):\n",
    "\t\tself.derivWeights = forwDeriv.dot(self.inp.T)\n",
    "\t\tself.derivBiases = forwDeriv\n",
    "\t\tself.derivIn = self.weights.T.dot(forwDeriv)\n",
    "\n",
    "\t\treturn self.derivIn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relu class :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class relu:\n",
    "\tdef __init__(self,inpSize):\n",
    "\t\tself.inpSize = inpSize\n",
    "\n",
    "\tdef forwardPass(self,inp):\n",
    "\t\tout1 = np.zeros((self.inpSize,1))\n",
    "\t\tfor i in range(self.inpSize):\n",
    "\t\t\tif inp[i,0] > 0:\n",
    "\t\t\t\tout1[i] = inp[i,0]\n",
    "\t\tself.out = out1\n",
    "\t\treturn out1\n",
    "\n",
    "\tdef backPass(self,forwDeriv):\n",
    "\t\tself.derivIn = np.zeros((self.inpSize,1))\n",
    "\t\tfor i in range(self.inpSize):\n",
    "\t\t\ttemp = 0\n",
    "\t\t\tif self.out[i] > 0:\n",
    "\t\t\t\ttemp = 1\n",
    "\t\t\tself.derivIn[i] = forwDeriv[i] * temp\n",
    "\t\treturn self.derivIn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax class :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class softMax:\n",
    "\tdef __init__(self,inpSize):\n",
    "\t\tself.inpSize = inpSize\n",
    "\n",
    "\tdef forwardPass(self,inp):\n",
    "\t\tout1 = np.exp(inp)\n",
    "\t\ttot = np.sum(out1)\n",
    "\t\tout1 = out1/tot \n",
    "\t\tself.out = out1\n",
    "\t\treturn out1\n",
    "\n",
    "\tdef backPass(self,forwDeriv):\n",
    "\t\tself.derivIn = np.zeros((self.inpSize,1))\n",
    "\t\ts = - self.out.dot(self.out.T)\n",
    "\t\tself.derivIn = s.dot(forwDeriv) + np.multiply(self.out,forwDeriv)\n",
    "\t\treturn self.derivIn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class to calculate cross - entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class crossEntropy:\n",
    "\tdef __init__(self,inpSize):\n",
    "\t\tself.inpSize = inpSize\n",
    "\n",
    "\tdef forwardPass(self,inp,expected):\n",
    "\t\tout1 = -expected.T.dot(np.log(inp))\n",
    "\t\tself.expected = expected\n",
    "\t\tself.inp = inp\n",
    "\t\tself.out = out1\n",
    "\t\treturn out1\n",
    "\n",
    "\tdef backPass(self,forwDeriv = None):\n",
    "\t\tself.derivIn = np.zeros((self.inpSize,1))\n",
    "\t\tfor i in range(self.inpSize):\n",
    "\t\t\tself.derivIn[i,0] = -self.expected[i,0]/self.inp[i,0]\n",
    "\t\treturn self.derivIn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy = 68% achieved\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as pl\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "\n",
    "# from layers import layer\n",
    "# from layers import relu\n",
    "# from layers import softMax\n",
    "# from layers import crossEntropy\n",
    "\n",
    "trainingSeries = np.load(\"../../cifar-10-batches-py/trainingSeries.npy\")\n",
    "testSeries = np.load(\"../../cifar-10-batches-py/testSeries.npy\")\n",
    "\n",
    "trainingSize = 3000\n",
    "validSize = 1000\n",
    "testSize = 1000\n",
    "numClasses = 2\n",
    "\n",
    "batchSize = 5\n",
    "eta = 0.007\n",
    "\n",
    "l1 = layer(3072,500)\n",
    "relu12 = relu(500)\n",
    "l2 = layer(500,100)\n",
    "relu23 = relu(100)\n",
    "l3 = layer(100,2)\n",
    "softMaxOut = softMax(2)\n",
    "loss = crossEntropy(2)\n",
    "weightShape1 = np.shape(l1.weights)\n",
    "weightShape2 = np.shape(l2.weights)\n",
    "weightShape3 = np.shape(l3.weights)\n",
    "biasesShape1 = np.shape(l1.biases)\n",
    "biasesShape2 = np.shape(l2.biases)\n",
    "biasesShape3 = np.shape(l3.biases)\n",
    "\n",
    "\n",
    "\n",
    "numItr = int(trainingSize/batchSize)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(numItr):\n",
    "\tprint(\"epoch \" + str(i))\n",
    "\n",
    "\tsample = np.array(trainingSeries[:,i*batchSize : (i+1)*batchSize])\n",
    "\tweights1 = np.zeros(weightShape1)\n",
    "\tweights2 = np.zeros(weightShape2)\n",
    "\tweights3 = np.zeros(weightShape3)\n",
    "\tbiases1 = np.zeros(biasesShape1)\n",
    "\tbiases2 = np.zeros(biasesShape2)\n",
    "\tbiases3 = np.zeros(biasesShape3)\n",
    "\n",
    "\tfor j in range(batchSize):\n",
    "\t\t\n",
    "\n",
    "\t\tfor k in range(numClasses):\n",
    "\t\t\tmat = np.zeros((numClasses,1))\t\t\t\n",
    "\t\t\tdataPoint = np.matrix(sample[k,j].astype('float64'))\n",
    "\t\t\tdataPoint = dataPoint.T / 256\n",
    "\t\t\tif k ==0:\n",
    "\t\t\t\tmat = np.matrix([[1],[0]])\n",
    "\t\t\telse:\n",
    "\t\t\t\tmat = np.matrix([[0],[1]])\n",
    "\n",
    "\t\t\to1=l1.forwardPass(dataPoint)\n",
    "\t\t\to2=relu12.forwardPass(o1)\n",
    "\t\t\to3=l2.forwardPass(o2)\n",
    "\t\t\to4=relu23.forwardPass(o3)\n",
    "\t\t\to5=l3.forwardPass(o4)\n",
    "\t\t\to6=softMaxOut.forwardPass(o5)\n",
    "\t\t\to7=loss.forwardPass(o6,mat)\n",
    "\n",
    "\t\t\tb7=loss.backPass()\n",
    "\t\t\tb6=softMaxOut.backPass(b7)\n",
    "\t\t\tb5=l3.backPass(b6)\n",
    "\t\t\tb4=relu23.backPass(b5)\n",
    "\t\t\tb3=l2.backPass(b4)\n",
    "\t\t\tb2=relu12.backPass(b3)\n",
    "\t\t\tb1=l1.backPass(b2)\n",
    "\n",
    "\t\t\tweights1 += l1.weights - eta * l1.derivWeights\n",
    "\t\t\tweights2 += l2.weights - eta * l2.derivWeights\n",
    "\t\t\tweights3 += l3.weights - eta * l3.derivWeights\n",
    "\t\t\tbiases1 += l1.biases - eta * l1.derivBiases\n",
    "\t\t\tbiases2 += l2.biases - eta * l2.derivBiases\n",
    "\t\t\tbiases3 += l3.biases - eta * l3.derivBiases\n",
    "\n",
    "\tl1.weights = weights1/(numClasses*batchSize)\n",
    "\tl2.weights = weights2/(numClasses*batchSize)\n",
    "\tl3.weights = weights3/(numClasses*batchSize)\n",
    "\tl1.biases = biases1/(numClasses*batchSize)\n",
    "\tl2.biases = biases2/(numClasses*batchSize)\t\n",
    "\tl3.biases = biases3/(numClasses*batchSize)\n",
    "\n",
    "\tcorrect = 0\n",
    "\n",
    "\tfor i in range(validSize):\n",
    "\t\tfor k in range(numClasses):\n",
    "\t\t\tdataPoint = np.matrix(trainingSeries[k,trainingSize + i].astype('float64'))\n",
    "\t\t\tdataPoint = dataPoint.T/256\n",
    "\t\t\to1=l1.forwardPass(dataPoint)\n",
    "\t\t\to2=relu12.forwardPass(o1)\n",
    "\t\t\to3=l2.forwardPass(o2)\n",
    "\t\t\to4=relu23.forwardPass(o3)\n",
    "\t\t\to5=l3.forwardPass(o4)\n",
    "\t\t\to6=softMaxOut.forwardPass(o5)\n",
    "\t\t\tif (k == 0 and o6[0] >= o6[1]) :\n",
    "\t\t\t\tcorrect += 1\n",
    "\t\t\tif (k == 1 and o6[0] <= o6[1]):\n",
    "\t\t\t\tcorrect += 1\n",
    "\n",
    "\taccuracy = 100*correct/(numClasses*validSize)\n",
    "\n",
    "\tprint(\"accuracy \" + str(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
